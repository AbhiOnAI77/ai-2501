{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cbb3c37",
   "metadata": {},
   "source": [
    "### Encoding & Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c429c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/anaconda3/lib/python3.12/site-packages (4.57.1)\n",
      "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.12/site-packages (2.9.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.34.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.22.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.9)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2025.4.26)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0d8b24d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62042f4914594eb8b8e7d40f3f59424d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66310cf964fd46c29a27e529caf5ae1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d65d52ab998249d9b2759903a4f622d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d7843ec3ee54bebaba6d5bedc7dcf82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045fcb81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['the', 'quarterly', 'sales', 'report', 'exceeded', 'expectations', '.']\n",
      "Tokens: ['the', 'quarterly', 'sales', 'report', 'exceeded', 'expectations', '.', 'art', '##ific', '##ally']\n"
     ]
    }
   ],
   "source": [
    "input1 = \"The quarterly sales report exceeded expectations.\"\n",
    "input2 = \"The quarterly sales report exceeded expectations. artifically\"\n",
    "\n",
    "# Step 1: Word Piece Tokenization\n",
    "tokens1 = tokenizer.tokenize(input1)\n",
    "print(\"Tokens:\", tokens1)\n",
    "\n",
    "tokens2 = tokenizer.tokenize(input2)\n",
    "print(\"Tokens:\", tokens2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fbb477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs for tokens1: [1996, 12174, 4341, 3189, 14872, 10908, 1012]\n",
      "\n",
      "Input IDs for tokens2: [1996, 12174, 4341, 3189, 14872, 10908, 1012, 2396, 18513, 3973]\n"
     ]
    }
   ],
   "source": [
    "# Step 2: IDs for tokens\n",
    "input_ids1 = tokenizer.convert_tokens_to_ids(tokens1)\n",
    "print(\"Input IDs for tokens1:\", input_ids1)\n",
    "print()\n",
    "input_ids2 = tokenizer.convert_tokens_to_ids(tokens2)\n",
    "print(\"Input IDs for tokens2:\", input_ids2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942375bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 1996, 12174, 4341, 3189, 14872, 10908, 1012, 2396, 18513, 3973, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note: Steps (1) and (2) are combined in the tokenizer's __call__ method and called encoding. \n",
    "\n",
    "encoding1 = tokenizer(input1)\n",
    "encoding1 \n",
    "encoding2 = tokenizer(input2) \n",
    "encoding2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "028d3bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded Input 1: [CLS] the quarterly sales report exceeded expectations. [SEP]\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Decoding from IDs back to text\n",
    "\n",
    "decoded_input = tokenizer.decode(encoding1['input_ids'])\n",
    "print(\"Decoded Input 1:\", decoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "576185b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 1996, 12174, 4341, 3189, 14872, 10908, 1012, 102], [101, 1045, 2293, 2478, 9932, 102, 0, 0, 0]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 0, 0, 0]]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4: Handle Missing Inputs / Sentences (Batch Encoding)\n",
    "\n",
    "inputs = [\n",
    "    'The quarterly sales report exceeded expectations.',\n",
    "    'I love using AI'\n",
    "]\n",
    "\n",
    "encoded_inputs = tokenizer(inputs, padding=True)\n",
    "\n",
    "encoded_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ef281b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 1996, 12174, 4341, 102], [101, 1045, 2293, 2478, 102]], 'token_type_ids': [[0, 0, 0, 0, 0], [0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1], [1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 5: Truncation (useful for cost control)\n",
    "\n",
    "inputs = [\n",
    "    'The quarterly sales report exceeded expectations.',\n",
    "    'I love using AI.'\n",
    "]\n",
    "\n",
    "encoded_inputs_trunc = tokenizer(inputs, padding=True, truncation=True, max_length=5)\n",
    "\n",
    "encoded_inputs_trunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee41632c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "726dc7cf9cb0416b84d6fdbf2299eccb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/996 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f727082c9b774261a2c002bc50dcebc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c3791f6ec204ef9b6ee609bb782e17c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5554bc44e97b459bb19eaf647aeaf1e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['The', 'Ġquarterly', 'Ġsales', 'Ġreport', 'Ġexceeded', 'Ġexpectations', '.']\n",
      "Tokens: ['▁The', '▁quarter', 'ly', '▁sales', '▁report', '▁exceed', 'ed', '▁expectations', '.']\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Explore other tokenizer models \n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# tokenizer1 = AutoTokenizer.from_pretrained(\"openai-community/gpt2\") \n",
    "tokenizer2 = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-v0.1\") \n",
    "\n",
    "input1 = \"The quarterly sales report exceeded expectations.\"\n",
    "\n",
    "tokens1 = tokenizer.tokenize(input1)\n",
    "print(\"Tokens:\", tokens1)\n",
    "print()\n",
    "tokens2 = tokenizer2.tokenize(input1)\n",
    "print(\"Tokens:\", tokens2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Anaconda)",
   "language": "python",
   "name": "anaconda_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
